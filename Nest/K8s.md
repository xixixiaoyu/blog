在 K8s 出现之前，我们是怎么部署应用的？

可能是在一台服务器上手动安装、配置、运行。后来应用变多了，服务器也变多了，问题就来了：

- **资源浪费**：一台服务器可能只跑了一个小应用，CPU 和内存大量闲置。
- **故障影响大**：这台服务器宕机，上面的应用就全挂了。
- **扩容缩容难**：流量高峰来了，想快速增加 10 个应用实例，怎么办？手动再部署 10 台服务器吗？流量过去了，这些多余的资源又怎么处理？
- **环境不一致**：开发环境、测试环境、生产环境配置总有差异，导致“在我电脑上是好的”这类问题。

所以核心问题在于：**如何高效、可靠、自动化地管理在大量服务器上运行的、相互隔离的应用？**

K8s（Kubernetes）就是为了解决这个问题而生的。你可以把它想象成一个**专门为“集群”设计的操作系统**。

它只关心：

1. 你要运行几个应用实例？
2. 它们需要多少 CPU 和内存？
3. 应用之间如何互相访问？
4. 如何保证它们一直健康地运行？

想象一个巨大、繁忙的自动化集装箱码头：

- **整个码头**：就是 K8s 的 **Cluster（集群）**，是所有资源的总和。
- **码头里的各种吊车、卡车、工人**：就是集群里的 **Node（节点）**，通常是一台物理机或虚拟机，是真正干活的。
- **标准化的集装箱**：就是 K8s 的 **Pod**。这是 K8s 世界里最基本的调度单元。一个 Pod 里可以装一个或多个紧密协作的“货物”（**容器**，比如 Docker 容器）。为什么需要 Pod？因为有些容器必须“绑”在一起，比如主应用容器和它的日志收集容器，它们必须被调度到同一个节点上，共享网络和存储。
- **码头的中央调度系统**：就是 K8s 的 **Master（或称 Control Plane）**。它是整个码头的大脑，负责接收指令、监控所有节点和集装箱的状态、并指挥吊车（Node）把集装箱（Pod）放到合适的地方。

现在，你是一个货主，要把一批货物（你的应用）运到这个码头。

你不需要亲自去指挥吊车，你只需要填写一张“货运需求单”，告诉调度系统你的“期望状态”。K8s 会自动化地让现实状态向你的期望状态靠拢。

这张“需求单”就是 K8s 的核心概念。

#### 1. Pod：最小的集装箱

Pod 是 K8s 中可以创建和管理的最小单元。

它像是一个“豆荚”，里面包裹着一个或多个容器。这些容器共享网络 IP 和存储资源，可以像在同一个机器上一样通过 `localhost` 通信。

#### 2. Deployment：你的“货运需求单”

这是最常用的“需求单”之一。你不会直接去创建 Pod，而是通过 Deployment 来声明你的应用状态。

在 Deployment 里，你会定义：

- **应用镜像**：比如 `nginx:1.23`。
- **副本数量**：比如 `3`，代表我想要我的应用一直有 3 个实例在运行。
- **更新策略**：比如“滚动更新”，即先启动一个新版本 Pod，再停一个旧版本 Pod，保证服务不中断。

当你把这张“需求单”提交给 K8s 后，它就会：

- 找到 3 个合适的 Node（吊车）。
- 在这些 Node 上创建 3 个 Pod（集装箱），里面装着你的 Nginx 应用。
- 持续监控这 3 个 Pod。如果其中一个挂了，K8s 会立刻在别的地方启动一个新的，确保总数始终是 3。这就是**自愈能力**。

#### 3. Service：稳定的“提货地址”

Pod 的生命周期是不固定的，它们会被创建、销毁，每次重建后 IP 地址都可能改变。

直接用 Pod IP 来访问应用显然是不可靠的。

Service 就是为了解决这个问题而生的。它为一组功能相同的 Pod（通常由 Deployment 管理）提供一个**稳定、统一的访问入口**（一个固定的虚拟 IP 和 DNS 名称）。

就像码头对外公布的那个提货地址，你只需要知道这个地址，至于你的货物具体在哪个集装箱、由哪辆卡车运送，你完全不用关心。Service 会自动将请求转发到它背后某个健康的 Pod 上。

### 动手写一张“需求单”

下面是一张部署 Nginx 的“需求单”（一个 YAML 文件）：

```yaml
# nginx-deployment.yaml
apiVersion: 'apps/v1' # 为什么是这个版本？因为 Deployment 是在 apps/v1 这个 API 组中定义的。
kind: 'Deployment'    # 为什么是 Deployment？因为我们想要一个自愈、可伸缩的应用。
metadata:
  name: 'nginx-deployment' # 给这个 Deployment 起个名字，方便管理。
spec:
  replicas: 3 # 为什么是 3？为了高可用性，如果一个挂了，还有两个在运行。
  selector:
    matchLabels:
      app: 'nginx' # 为什么需要 selector？为了让 Deployment 知道它应该管理哪些 Pod。
  template:        # 这是 Pod 的模板，Deployment 会根据它来创建 Pod。
    metadata:
      labels:
        app: 'nginx' # 为什么这里要加标签？为了与上面的 selector 匹配，建立管理关系。
    spec:
      containers:
        - name: 'nginx' # 容器的名字。
          image: 'nginx:1.23' # 为什么指定版本？为了保证环境的一致性和可复现性。
          ports:
            - containerPort: 80 # 容器内部监听的端口。
```

你只需要用 `kubectl apply -f nginx-deployment.yaml` 这条命令把这张“需求单”提交给 K8s，剩下的事情，它就全帮你搞定了。



### 总结一下

K8s 的核心，就是**“声明式”的“期望状态管理”**。

你不需要告诉它“第一步做什么，第二步做什么”，你只需要告诉它“我最终想要什么样子”，它就会像一个尽职尽责的管家，调动所有资源，并持续不断地维持这个状态。

- **Pod** 是最小的运行单元。
- **Deployment** 定义了应用的“期望状态”（副本数、版本等）。
- **Service** 为应用提供一个稳定的访问入口。
- **Cluster** 是所有 Node 和 Pod 的集合，是 K8s 发挥作用的舞台。

