# Python 内存管理

## 最佳提示词

```
请详细介绍 Python 的内存管理，包括以下内容：

1. 内存管理基础：
   - Python 内存模型
   - 对象内存布局
   - 引用计数机制
   - 垃圾回收原理

2. 内存分析工具：
   - 内存监控方法
   - 内存泄漏检测
   - 对象跟踪技术
   - 内存快照分析

3. 内存优化技巧：
   - 对象池化
   - 弱引用使用
   - 生成器优化
   - 数据结构选择

4. 垃圾回收优化：
   - GC 算法理解
   - GC 调优参数
   - 分代回收机制
   - 循环引用处理

5. 内存管理最佳实践：
   - 大对象处理
   - 缓存策略
   - 资源释放模式
   - 内存限制设置

6. 高级内存技术：
   - 内存映射文件
   - 共享内存
   - 自定义内存分配器
   - C 扩展内存管理

请为每个概念提供详细的代码示例，包括实际应用场景和内存分析。
```

## 学习要点

- 理解 Python 的内存管理机制
- 掌握内存分析和监控方法
- 学会识别和解决内存泄漏
- 了解垃圾回收的工作原理
- 掌握内存优化的技巧
- 学会处理大内存应用场景

## 实践练习

1. 使用工具分析内存使用
2. 检测和修复内存泄漏
3. 实现高效的内存管理
4. 优化垃圾回收参数
5. 处理大内存数据集

## 代码示例模板

```python
import gc
import sys
import tracemalloc
import objgraph
import weakref
import psutil
import os
import time
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from contextlib import contextmanager
import pickle
import mmap
import array
import numpy as np

# 内存管理基础
def memory_management_basics():
    """内存管理基础示例"""
    
    # 对象内存大小
    a = 42
    b = "hello world"
    c = [1, 2, 3, 4, 5]
    d = {'key': 'value'}
    
    print(f"整数对象大小: {sys.getsizeof(a)} 字节")
    print(f"字符串对象大小: {sys.getsizeof(b)} 字节")
    print(f"列表对象大小: {sys.getsizeof(c)} 字节")
    print(f"字典对象大小: {sys.getsizeof(d)} 字节")
    
    # 引用计数
    print(f"\n整数引用计数: {sys.getrefcount(a)}")
    print(f"字符串引用计数: {sys.getrefcount(b)}")
    
    # 创建引用
    ref_a = a
    print(f"创建引用后整数引用计数: {sys.getrefcount(a)}")
    
    # 删除引用
    del ref_a
    print(f"删除引用后整数引用计数: {sys.getrefcount(a)}")

# 垃圾回收机制
def garbage_collection_mechanism():
    """垃圾回收机制示例"""
    
    # 获取 GC 信息
    print(f"GC 阈值: {gc.get_threshold()}")
    print(f"GC 计数: {gc.get_count()}")
    
    # 创建循环引用
    class Node:
        def __init__(self, name):
            self.name = name
            self.parent = None
            self.children = []
        
        def add_child(self, child):
            self.children.append(child)
            child.parent = self
        
        def __repr__(self):
            return f"Node({self.name})"
    
    # 创建循环引用
    parent = Node("parent")
    child = Node("child")
    parent.add_child(child)
    
    print(f"\n创建循环引用后:")
    print(f"GC 计数: {gc.get_count()}")
    
    # 手动触发垃圾回收
    collected = gc.collect()
    print(f"手动GC回收对象数: {collected}")
    print(f"GC后计数: {gc.get_count()}")
    
    # 删除引用
    del parent, child
    
    # 再次触发垃圾回收
    collected = gc.collect()
    print(f"删除引用后GC回收对象数: {collected}")
    print(f"最终GC计数: {gc.get_count()}")

# 内存泄漏检测
def memory_leak_detection():
    """内存泄漏检测示例"""
    
    # 启动内存跟踪
    tracemalloc.start()
    
    # 记录初始内存
    snapshot1 = tracemalloc.take_snapshot()
    
    # 创建可能导致内存泄漏的代码
    leaked_objects = []
    
    def create_leaky_objects():
        """创建可能导致泄漏的对象"""
        for i in range(1000):
            # 创建对象并保持引用
            obj = {
                'id': i,
                'data': 'x' * 100,  # 较大的字符串
                'nested': {
                    'info': f"item_{i}",
                    'more_data': list(range(10))
                }
            }
            leaked_objects.append(obj)
    
    # 执行泄漏代码
    create_leaky_objects()
    
    # 记录当前内存
    snapshot2 = tracemalloc.take_snapshot()
    
    # 比较内存快照
    top_stats = snapshot2.compare_to(snapshot1, 'lineno')
    
    print("\n内存增长前10:")
    for stat in top_stats[:10]:
        print(stat)
    
    # 使用 objgraph 分析
    print("\n对象类型统计:")
    objgraph.show_most_common_types(limit=10)
    
    # 清理
    del leaked_objects
    gc.collect()

# 弱引用使用
def weak_reference_usage():
    """弱引用使用示例"""
    
    class CachedObject:
        """缓存对象类"""
        def __init__(self, data):
            self.data = data
        
        def __repr__(self):
            return f"CachedObject({self.data})"
    
    # 创建弱引用字典
    weak_cache = weakref.WeakValueDictionary()
    
    def get_cached_object(key):
        """获取缓存对象"""
        obj = weak_cache.get(key)
        if obj is None:
            obj = CachedObject(f"data_for_{key}")
            weak_cache[key] = obj
            print(f"创建新对象: {obj}")
        else:
            print(f"从缓存获取: {obj}")
        return obj
    
    # 测试缓存
    obj1 = get_cached_object(1)
    obj2 = get_cached_object(2)
    obj3 = get_cached_object(1)  # 应该从缓存获取
    
    print(f"\n缓存大小: {len(weak_cache)}")
    
    # 创建强引用
    strong_ref = weak_cache[1]
    print(f"创建强引用: {strong_ref}")
    
    # 删除强引用
    del strong_ref
    gc.collect()
    
    print(f"垃圾回收后缓存大小: {len(weak_cache)}")

# 对象池化
class ObjectPool:
    """对象池类"""
    
    def __init__(self, create_func, max_size=10):
        self.create_func = create_func
        self.max_size = max_size
        self.pool = []
        self.in_use = weakref.WeakSet()
    
    def acquire(self):
        """获取对象"""
        if self.pool:
            obj = self.pool.pop()
        else:
            obj = self.create_func()
        
        self.in_use.add(obj)
        return obj
    
    def release(self, obj):
        """释放对象"""
        if obj in self.in_use and len(self.pool) < self.max_size:
            self.pool.append(obj)
            self.in_use.discard(obj)
    
    def stats(self):
        """池统计信息"""
        return {
            'pool_size': len(self.pool),
            'in_use': len(self.in_use),
            'max_size': self.max_size
        }

def object_pooling_example():
    """对象池化示例"""
    
    class ExpensiveObject:
        """昂贵对象类"""
        def __init__(self):
            self.data = list(range(1000))  # 模拟昂贵初始化
            print(f"创建昂贵对象 {id(self)}")
        
        def reset(self):
            """重置对象状态"""
            self.data = []
    
    # 创建对象池
    pool = ObjectPool(lambda: ExpensiveObject(), max_size=3)
    
    # 使用对象池
    objects = []
    for i in range(5):
        obj = pool.acquire()
        objects.append(obj)
        print(f"获取对象 {i}: {id(obj)}")
    
    print(f"\n池状态: {pool.stats()}")
    
    # 释放对象
    for i, obj in enumerate(objects):
        pool.release(obj)
        print(f"释放对象 {i}: {id(obj)}")
    
    print(f"\n释放后池状态: {pool.stats()}")

# 内存映射文件
def memory_mapped_file_example():
    """内存映射文件示例"""
    
    # 创建测试文件
    filename = 'test_mmap.dat'
    
    # 写入数据到文件
    with open(filename, 'wb') as f:
        data = b'Hello, Memory Mapped File!' * 1000
        f.write(data)
    
    # 内存映射文件
    with open(filename, 'r+b') as f:
        # 创建内存映射
        mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)
        
        print(f"映射文件大小: {len(mm)} 字节")
        print(f"前100字节: {mm[:100]}")
        
        # 搜索内容
        position = mm.find(b'Memory')
        if position != -1:
            print(f"找到'Memory'在位置: {position}")
        
        # 关闭内存映射
        mm.close()
    
    # 清理
    os.remove(filename)

# 大对象处理
def large_object_handling():
    """大对象处理示例"""
    
    # 使用生成器处理大文件
    def process_large_file(filename):
        """处理大文件的生成器"""
        with open(filename, 'r') as f:
            for line in f:
                # 逐行处理，避免一次性加载整个文件
                yield line.strip().lower()
    
    # 使用数组模块处理数值数据
    def process_numeric_data():
        """使用数组模块处理数值数据"""
        # 比列表更节省内存
        numbers = array.array('i', range(1000000))
        
        # 计算总和
        total = sum(numbers)
        print(f"数值总和: {total}")
        
        # 内存使用对比
        list_size = sys.getsizeof(list(range(1000000)))
        array_size = sys.getsizeof(numbers)
        print(f"列表大小: {list_size} 字节")
        print(f"数组大小: {array_size} 字节")
        print(f"内存节省: {(list_size - array_size) / 1024:.2f} KB")
    
    # 使用 NumPy 处理大数据
    def process_with_numpy():
        """使用 NumPy 处理大数据"""
        # NumPy 数组比 Python 列表更节省内存
        data = np.arange(1000000, dtype=np.int32)
        
        # 向量化操作
        squared = data ** 2
        mean_value = np.mean(squared)
        
        print(f"平方后平均值: {mean_value}")
        
        # 内存使用对比
        list_memory = sys.getsizeof(list(range(1000000)))
        numpy_memory = data.nbytes
        print(f"Python列表内存: {list_memory} 字节")
        print(f"NumPy数组内存: {numpy_memory} 字节")
    
    process_numeric_data()
    process_with_numpy()

# 内存监控装饰器
def memory_monitor(func):
    """内存监控装饰器"""
    def wrapper(*args, **kwargs):
        # 记录初始内存
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # 启动内存跟踪
        tracemalloc.start()
        
        try:
            result = func(*args, **kwargs)
            
            # 记录峰值内存
            current, peak = tracemalloc.get_traced_memory()
            peak_memory = peak / 1024 / 1024  # MB
            
            final_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            print(f"函数 {func.__name__} 内存使用:")
            print(f"  初始内存: {initial_memory:.2f} MB")
            print(f"  峰值内存: {peak_memory:.2f} MB")
            print(f"  最终内存: {final_memory:.2f} MB")
            print(f"  内存增长: {final_memory - initial_memory:.2f} MB")
            
            return result
        
        finally:
            tracemalloc.stop()
    
    return wrapper

@memory_monitor
def memory_intensive_function():
    """内存密集型函数"""
    # 创建大量对象
    large_list = []
    for i in range(100000):
        large_list.append({
            'id': i,
            'data': 'x' * 100,
            'nested': list(range(10))
        })
    
    # 模拟处理
    time.sleep(0.1)
    
    return len(large_list)

# 上下文管理器用于资源管理
@contextmanager
def memory_limited_context(max_memory_mb=100):
    """内存限制上下文管理器"""
    process = psutil.Process(os.getpid())
    initial_memory = process.memory_info().rss / 1024 / 1024
    
    try:
        yield
    finally:
        final_memory = process.memory_info().rss / 1024 / 1024
        memory_used = final_memory - initial_memory
        
        if memory_used > max_memory_mb:
            print(f"警告: 内存使用 {memory_used:.2f} MB 超过限制 {max_memory_mb} MB")
        else:
            print(f"内存使用: {memory_used:.2f} MB 在限制范围内")

def memory_management_example():
    """内存管理示例"""
    
    with memory_limited_context(max_memory_mb=50):
        # 在内存限制下执行操作
        data = []
        for i in range(10000):
            data.append(i * i)
        
        print(f"处理了 {len(data)} 个数据项")

# 自定义内存分配器
class MemoryAllocator:
    """自定义内存分配器"""
    
    def __init__(self, block_size=1024):
        self.block_size = block_size
        self.blocks = []
        self.free_blocks = []
    
    def allocate(self, size):
        """分配内存块"""
        # 查找合适的空闲块
        for i, block in enumerate(self.free_blocks):
            if len(block) >= size:
                self.free_blocks.pop(i)
                return block[:size]
        
        # 创建新块
        new_block = bytearray(self.block_size)
        self.blocks.append(new_block)
        return new_block[:size]
    
    def deallocate(self, block):
        """释放内存块"""
        self.free_blocks.append(block)
    
    def stats(self):
        """分配器统计"""
        total_allocated = len(self.blocks) * self.block_size
        total_free = sum(len(block) for block in self.free_blocks)
        
        return {
            'total_blocks': len(self.blocks),
            'free_blocks': len(self.free_blocks),
            'total_allocated': total_allocated,
            'total_free': total_free
        }

def custom_allocator_example():
    """自定义分配器示例"""
    
    allocator = MemoryAllocator(block_size=2048)
    
    # 分配内存
    block1 = allocator.allocate(100)
    block2 = allocator.allocate(200)
    block3 = allocator.allocate(300)
    
    print(f"分配器状态: {allocator.stats()}")
    
    # 释放内存
    allocator.deallocate(block1)
    allocator.deallocate(block2)
    
    print(f"释放后状态: {allocator.stats()}")

# 内存压力测试
def memory_stress_test():
    """内存压力测试"""
    
    def allocate_and_monitor(size_mb):
        """分配内存并监控"""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024
        
        # 分配内存
        data = bytearray(size_mb * 1024 * 1024)
        
        final_memory = process.memory_info().rss / 1024 / 1024
        actual_increase = final_memory - initial_memory
        
        print(f"分配 {size_mb} MB:")
        print(f"  预期增长: {size_mb} MB")
        print(f"  实际增长: {actual_increase:.2f} MB")
        print(f"  效率: {actual_increase/size_mb:.2f}")
        
        return data
    
    try:
        # 逐步增加内存分配
        blocks = []
        for size in [10, 50, 100, 200]:
            block = allocate_and_monitor(size)
            blocks.append(block)
            time.sleep(0.1)
        
        # 清理
        for block in blocks:
            del block
        
        gc.collect()
        
    except MemoryError:
        print("内存不足，无法继续分配")

# 主函数
def main():
    """主函数，运行所有内存管理示例"""
    print("=== 内存管理基础 ===")
    memory_management_basics()
    
    print("\n=== 垃圾回收机制 ===")
    garbage_collection_mechanism()
    
    print("\n=== 内存泄漏检测 ===")
    memory_leak_detection()
    
    print("\n=== 弱引用使用 ===")
    weak_reference_usage()
    
    print("\n=== 对象池化 ===")
    object_pooling_example()
    
    print("\n=== 内存映射文件 ===")
    memory_mapped_file_example()
    
    print("\n=== 大对象处理 ===")
    large_object_handling()
    
    print("\n=== 内存监控 ===")
    memory_intensive_function()
    
    print("\n=== 内存管理上下文 ===")
    memory_management_example()
    
    print("\n=== 自定义分配器 ===")
    custom_allocator_example()
    
    print("\n=== 内存压力测试 ===")
    memory_stress_test()

if __name__ == "__main__":
    main()
```

## 扩展资源

- [gc 模块文档](https://docs.python.org/3/library/gc.html)
- [tracemalloc 模块文档](https://docs.python.org/3/library/tracemalloc.html)
- [weakref 模块文档](https://docs.python.org/3/library/weakref.html)
- [objgraph 文档](https://pypi.org/project/objgraph/)
- [psutil 文档](https://psutil.readthedocs.io/)
- [Python 内存管理指南](https://docs.python.org/3/c-api/memory.html)