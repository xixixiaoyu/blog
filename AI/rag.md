大模型是一个基于海量数据训练的知识库，模型训练完成，知识就被固定了。

RAG（Retrieval-Augmented Generation，检索增强生成）就是将**信息检索（Retrieval）** 系统与**文本生成（Generation）** 模型的能力解耦并重新组合。

说白了就是让大模型能查资料。试图解决幻觉和静态知识的缺点。



### 步骤

1. 索引
   1. **加载与分块**：将长文档切分成更小的、语义完整的“文本块”
   1. **向量化**：使用一个嵌入模型将这些文本块转换为**向量**
   1. **存储**：将这些向量及其对应的原始文本存储到专门的**向量数据库**中
   
1. 检索
   1. **查询向量化**：将用户的查询语句（Query）使用**同一个嵌入模型**转换为查询向量
   1. **相似性搜索**：在向量数据库中，进行**相似度计算**，找出与查询向量最接近的 K 个文本块向量。这个过程非常高效
   1. **返回上下文**：将这 K 个最相关的原始文本块作为“上下文”提取出来
   
1. 生成
   1. 让大模型基于检索到的上下文和用户的问题，生成一个高质量的答案，比如：
   
      ```
      请严格根据以下提供的信息来回答问题。如果信息不足以回答问题，请直接说明你不知道。
      
      【相关信息开始】
      {这里插入检索到的上下文}
      【相关信息结束】
      
      问题：{用户的问题}
      答案：
      
      ```



rag 的适用场景有：**客服机器人**、**知识库问答**、**AI 辅助研究**、**内容创作与事实核查**。