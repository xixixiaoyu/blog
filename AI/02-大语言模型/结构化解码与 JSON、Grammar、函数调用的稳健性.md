# 写作提示 —— 为 AI Agent 建立“通信协议与行为准则”：一本关于结构化输出与工具调用的稳健性工程指南

**核心目标**：创作一篇面向 AI 工程师和架构师的、关于如何构建生产级可靠的 LLM 应用的深度工程指南。本文的核心是解决从“自由对话”到“可靠执行”的鸿沟，确保 AI Agent 的输出是可预测、可解析、可恢复且安全的。

**核心类比**：将构建稳健的 LLM 应用，比作**为一个强大但行为不羁的 AI Agent 定义一套严格的“通信协议（结构化输出）与行为准则（工具调用）”，并为其配备完善的“异常处理和安全审查机制”**。

---

### 1. 生成要求

- **读者画像**：正在或计划将 LLM 应用于生产环境，需要解决输出可靠性和系统集成问题的 AI 工程师、后端工程师和系统架构师。
- **风格**：极度务实，充满防御性编程思维。提供清晰的模式、反模式、代码示例和流程图，强调工程权衡和最佳实践。
- **结构**：遵循“定义协议 -> 定义行为 -> 设计容错 -> 建立品控”的逻辑，引导读者构建一个从内到外都足够稳健的系统。

---

### 2. 内容大纲

**引言：从“创意伙伴”到“可靠员工”**

-   开篇点题：当 LLM 从一个聊天机器人（创意伙伴）转变为需要接入真实业务系统的 AI Agent（可靠员工）时，其输出的“可靠性”就从一个加分项，变成了生死线。
-   引出核心类比：我们的任务，就是为这位新“员工”建立一套清晰的岗前培训和行为守则。

**第一章：定义“通信语言”—— 结构化输出的三重境界**

1.  **境界一：JSON 字符串 —— “君子协定”**
    *   **做法**：通过提示词（Prompt）要求模型输出 JSON 格式的字符串。
    *   **优点**：简单、快速，无需特定工具支持。
    *   **缺点（反模式）**：极不可靠。模型可能输出非 JSON 字符串、幻觉出额外字段、缺少必需字段、搞错数据类型。解析代码非常脆弱。
2.  **境界二：JSON Schema —— “格式合同”**
    *   **做法**：使用 `response_format={ "type": "json_object" }` (如 OpenAI 的 JSON Mode) 或其他框架提供的 Schema 约束功能。
    *   **优点**：模型被**强制**输出语法正确的 JSON，从根本上解决了“解析失败”的问题。
    *   **缺点**：只能保证**语法正确**，无法保证**内容合规**（如字段值是否在枚举范围内，字符串是否匹配特定正则表达式）。
3.  **境界三：Grammar-based Decoding —— “语法编译器”**
    *   **做法**：使用 GBNF (如在 `llama.cpp` 中) 或其他库（如 `outlines`, `guidance`）提供的形式化语法，在 Token 生成的每一步进行约束。
    *   **优点**：**完全保证**输出严格符合预定义的任意复杂语法（不止是 JSON），实现 100% 的结构正确性。这是目前可靠性的天花板。
    *   **缺点**：实现相对复杂，需要学习特定的语法描述语言。

**第二章：定义“行动能力”—— 安全的工具调用 (Tool Use) 模式**

1.  **核心原则：AI 只是“建议者”，你的代码才是“执行者”**
2.  **安全的工具调用实现模式（流程图 + 代码示例）**
    1.  **AI 生成调用意图**：LLM 的唯一输出是一个指定了工具名称和参数的 JSON 对象，如 `{"tool_name": "send_email", "arguments": {"to": "...", "subject": "..."}}`。
    2.  **宿主环境解析与严格校验**：你的后端代码负责解析此 JSON。**必须**使用 Pydantic 或类似工具，根据预定义的 Schema 严格校验参数的类型、范围、权限。
    3.  **在沙箱中执行**：工具的实际执行应在隔离的环境（如 Docker 容器、独立的进程）中进行，防止对主系统产生非预期影响（特别是文件系统、网络访问等操作）。
    4.  **将执行结果返回给 AI**：将工具的执行结果（成功信息、业务数据或错误堆栈）作为新的上下文传回给模型，让其决定下一步行动。

**第三章：构建“容错系统”—— 优雅地处理通信与行动的失败**

1.  **错误分类**：可恢复的（瞬时错误、轻微格式错误） vs. 不可恢复的（持续性逻辑错误、权限问题）。
2.  **容错模式 (Fault Tolerance Patterns)**
    *   **简单重试 (Retry)**：适用于网络波动等瞬时错误。
    *   **带修复指令的重试 (Retry with Repair Instructions)**：当解析失败或校验不通过时，将错误信息和原始输出一起发回给模型，明确指示它“修正错误并重试”。
    *   **优雅降级 (Graceful Degradation)**：多次尝试后依然失败，系统应有降级路径，如转为人工审核、返回通用友好提示，或调用一个更简单的、不依赖 LLM 的备用逻辑。
3.  **幂等性 (Idempotence)：防止“重复执行”的护栏**
    *   强调所有工具的实现都必须是幂等的。例如，`create_order` 函数内部应检查订单是否已存在，避免重复创建。这是保证系统状态一致性的关键。

**第四章：建立“质量保证”—— 持续的评估与回归测试**

1.  **北极星指标：结构化正确率**
    *   定义为“模型输出可被成功解析并通过业务逻辑校验的比例”。这是衡量系统稳健性的核心指标。
2.  **失败模式分析**
    *   定期对解析或校验失败的案例进行聚类分析，以确定是提示词需要优化、Grammar 需要增强，还是工具的错误处理需要改进。
3.  **端到端回归测试集**
    *   建立一套覆盖核心业务场景、包含各种边界情况的“红线”用例集。将其纳入 CI/CD 流程，确保任何代码或模型的变更都不会破坏系统的可靠性。

**结论：稳健性是 AI 工程化的基石**

-   总结从实验到生产，最大的挑战在于构建一个可信、可靠、可维护的系统。
-   强调结构化、容错和持续评估是实现这一目标的必经之路。

---

### 3. 质量检查清单

- [ ] **可靠性**：是否详细对比了不同结构化输出方案的可靠性，并给出了明确的选型建议？
- [ ] **安全性**：是否提供了具体、可操作的安全工具调用模式，并强调了校验和沙箱的重要性？
- [ ] **可恢复性**：是否提供了多种错误处理和容错模式，并解释了其适用场景？
- [ ] **幂等性**：是否强调了工具幂等性的重要性，并给出了实现思路？
- [ ] **可评估性**：是否定义了清晰的评估指标和回归测试策略，以实现长期的质量保证？

