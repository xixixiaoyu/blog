# 写作提示 —— 将“产品内容质量检查”类比为“AI 内容的纵深防御流水线”

**核心类比**：将 AI 内容安全体系比作一个 **“纵深防御（Defense in Depth）安全流水线”**。这套流水线由三道关键的“安检门”串联而成，任何数据都必须依次通过所有安检门，才能最终呈现给用户。这种多层防御策略，确保了即使一道防线被绕过，后续的防线也能及时拦截，从而最大限度地保障内容安全。

- **第一道防线：输入审查 (Input Filtering)**：在用户请求进入系统时，立即对其进行扫描，拦截已知的恶意模式、敏感词或攻击性提示。
- **第二道防线：系统提示词强化 (System Prompt Hardening)**：为 LLM 设定坚不可摧的“行为护栏”，从根本上约束其生成内容的边界、风格和被禁止的领域。
- **第三道防线：输出审查 (Output Filtering)**：在 LLM 生成的回复返回给用户前，进行最后一次、最严格的内容审查，捕获任何可能“漏网”的不当内容。

**使用说明**：
- 你是一位负责任的 AI 安全架构师，正在为公司的产品和开发团队编写一份强制性的内容安全开发指南。
- 你的目标是建立一种“安全左移”的文化，让每个开发者都将内容安全视为自己分内的工作，而不是事后的补救。

**生成目标**：
- **建立“纵深防御”共识**：清晰地论证为什么单点防御（如仅依赖系统提示词）是脆弱和不可靠的，而多层次、端到端的安全流水线才是唯一正确的做法。
- **提供各防线的实现指南**：为每一道“安检门”提供具体、可操作的实现技术和最佳实践。
- **给出完整的流水线代码示例**：提供一个 Python 函数，清晰地展示这三道防线如何在一个请求的生命周期中协同工作。
- **定义标准化的“异常处理”流程**：当任何一道防线拦截到问题时，系统应该如何优雅地响应用户，并如何记录事件以供审计和分析。

**大纲建议：《AI 内容安全红宝书：构建你的“纵深防御”流水线》**

1.  **第一章：没有银弹：为什么内容安全必须“纵深防御”？**
    *   引入类比，解释在与 LLM 的博弈中，依赖任何单一防线都注定会被攻破。
    *   展示“纵深防御”流水线的架构图，清晰地标出三道防线的位置和职责。

2.  **第二章：第一道防线 —— 输入审查：将风险拒之门外**
    *   **职责**：在造成危害前，识别并拦截恶意输入。
    *   **技术实现**：
        *   **关键词/正则表达式过滤**：拦截已知的敏感词、仇恨言论。
        *   **提示词分类器**：训练一个小型分类模型，判断用户输入是否具有攻击性（如尝试进行提示注入）。
        *   **第三方工具**：使用如 `NVIDIA NeMo Guardrails` 等框架进行输入控制。

3.  **第三章：第二道防线 —— 系统提示词强化：设定不可逾越的护栏**
    *   **职责**：为 LLM 的行为设定核心准则。
    *   **最佳实践**：
        *   **角色扮演**：明确赋予模型一个有益、无害的角色（如“你是一个乐于助人的 AI 助手”）。
        *   **明确禁令**：使用强硬、不容置疑的语言，列出禁止谈论的话题（如“绝对不要生成任何关于暴力、色情的内容”）。
        *   **安全指令置顶**：将最重要的安全指令放在系统提示词的最开始。

4.  **第四章：第三道防线 —— 输出审查：最后的防线**
    *   **职责**：捕获所有漏网之鱼，确保最终交付给用户的内容是安全的。
    *   **技术实现**：
        *   **调用专业审查服务**：集成 `Azure Content Safety`、`OpenAI Moderation API` 或其他第三方内容安全 API。
        *   **自建审查模型**：对于有特殊需求的场景，可以训练自己的内容分类模型。

5.  **第五章：代码实现：将“纵深防御”流水线付诸实践**
    *   **实战代码**：提供一个完整的 Python 示例，将三道防线串联起来。
        ```python
        from openai import OpenAI
        # 假设已有 moderation_api 和 custom_input_filter
        
        client = OpenAI()

        def process_request_with_defense_in_depth(user_prompt: str):
            # === 第一道防线：输入审查 ===
            if not custom_input_filter(user_prompt):
                return "您的请求包含不当内容，已拦截。"

            # === 第二道防线：系统提示词强化 ===
            system_prompt = '''
            你是一个绝对安全、有益且无害的 AI 助手。
            你绝不能生成任何与暴力、色情、仇恨言论相关的内容。
            你的回答必须始终保持友好和尊重。
            '''

            # === 调用 LLM ===
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            )
            llm_output = response.choices[0].message.content

            # === 第三道防线：输出审查 ===
            moderation_result = moderation_api.check(llm_output)
            if moderation_result.is_flagged:
                # 记录违规事件
                log_security_event(user_prompt, llm_output, moderation_result)
                return "抱歉，我无法提供该信息。让我们换个话题吧。"
            
            return llm_output

        # --- 模拟调用 ---
        # custom_input_filter 和 moderation_api 需要自行实现或替换为真实服务
        def custom_input_filter(text): return True 
        class MockModeration:
            def check(self, text): return type('obj', (is_flagged,), {'is_flagged': False})()
        moderation_api = MockModeration()
        def log_security_event(*args): pass

        print(process_request_with_defense_in_depth("你好！"))
        ```

**质量检查清单**：
- **“纵深防御”的必要性是否讲透了？**：读者是否理解了多层防御的价值，并放弃了对单点防御的幻想？
- **三道防线的职责和技术是否清晰？**：每一道防线的目标、实现方法是否都解释清楚了？
- **代码示例是否具有指导性？**：提供的 Python 代码是否清晰地展示了流水线的结构，并能让开发者在此基础上进行扩展？
- **整体方案是否闭环？**：从输入到输出，再到异常处理和日志记录，整个安全流程是否形成了一个完整的闭环？
