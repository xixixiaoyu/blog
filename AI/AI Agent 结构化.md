当你与一个 LLM 聊天时，它是一位充满奇思妙想的“创意伙伴”。它的回答天马行空，充满惊喜，偶尔的错误也无伤大雅。但当你将 LLM 接入生产系统，让它处理订单、查询数据库、发送邮件时，它的角色就必须转变为一位一丝不苟的“可靠员工”。

对于这位新“员工”，输出的“可靠性”不再是加分项，而是生死线。一次格式错误的 JSON 可能导致整个业务流程中断；一个未经校验的工具调用参数可能引发灾难性的数据操作。

因此，我们的核心任务，就是为这位强大但行为不羁的“员工”建立一套清晰的**岗前培训手册**。

这本手册包含两部分：

- 一是定义它如何与我们沟通的**“通信协议”（结构化输出）**。**

- **二是规定它能做什么、不能做什么的**“行为准则”（工具调用）**。同时，我们还要为它配备完善的**“异常处理和安全审查机制”**，确保它在任何情况下都能稳定、安全地工作。



要让 AI 的输出可预测、可解析，我们必须约束它的“语言”。结构化输出正是为此而生，但其可靠性存在明显的境界差异。



### 境界一：JSON 字符串 —— “君子协定”

这是最原始、最直接的方式。在提示词（Prompt）中明确要求模型输出 JSON 格式的字符串：

```
请分析以下用户反馈，并以 JSON 格式返回分析结果，包含 'sentiment' (positive/negative/neutral) 和 'key_topics' (字符串数组) 两个字段。
用户反馈："这个产品的界面设计很棒，但是加载速度太慢了。"
```

但是很明显，这是一种“君子协定”，全凭模型的“自觉”。



### 境界二：JSON Schema —— “格式合同”

使用 API 提供的结构化输出功能。例如，OpenAI 的 `response_format={ "type": "json_object" }`，并结合提示词指定 Schema：

```
# 伪代码
response = openai.chat.completions.create(
  model="gpt-4-turbo",
  messages=[...],
  response_format={"type": "json_object"}
)
```

模型被**强制**输出语法正确的 JSON。从根本上解决了“解析失败”的问题，你的代码可以放心地使用 `json.loads()`。

但是只能保证**语法正确**，无法保证**内容合规**。模型依然可以输出语法正确但业务上无效的值。

例如，你要求 `sentiment` 字段必须是 `positive/negative/neutral` 之一，但模型可能返回 `{"sentiment": "好评"}`。这虽然是一个合法的 JSON 字符串，但你的业务逻辑无法处理。





### 境界三：Grammar-based Decoding —— “语法编译器”

这是目前结构化输出的可靠性天花板。

使用形式化语法（如 GBNF - Guided BNF）在 Token 生成的每一步进行硬性约束。像 `llama.cpp`、`outlines`、`guidance` 等库都支持这种模式。

你需要定义一个精确的语法规则，例如：

```
root ::= "{" ws "\"sentiment\"" ws ":" ws sentiment "," ws "\"key_topics\"" ws ":" ws "[" ws topic ("," ws topic)* ws "]" ws "}"
sentiment ::= "\"positive\"" | "\"negative\"" | "\"neutral\""
topic ::= "\"" [^"]* "\""
ws ::= [ \t\n]*
```

**完全保证**输出严格符合预定义的任意复杂语法。它不仅能保证 JSON 语法正确，还能保证字段值在枚举范围内、字符串匹配正则表达式等。实现了 100% 的结构正确性，彻底消除了输出不确定性。

但是现相对复杂，需要学习特定的语法描述语言，且并非所有模型服务都原生支持。



**选型建议**：

- **快速原型**：境界一。
- **生产环境（追求可靠性）**：至少境界二，并配合后端严格校验。
- **关键任务系统（追求极致可靠性）**：境界三。







## 第二章：定义“行动能力”—— 安全的工具调用 模式

工具调用让 AI Agent 能够与外部世界交互，但这也是风险最高的环节。必须遵循防御性编程的最高原则。

永远不要直接执行 AI 生成的代码或命令。AI 的角色仅限于生成一个“调用建议”，一个包含工具名称和参数的结构化数据。真正的执行权必须牢牢掌握在你的宿主程序手中。

这个调用流程可以分为四个关键步骤，缺一不可：

<img src="./assets/image-20251121182123424.png" width="500" />

LLM 的唯一输出应该是一个结构化的调用指令，例如：

```json
{
  "tool_name": "send_email",
  "arguments": {
    "to": "user@example.com",
    "subject": "您的订单已发货",
    "body": "尊敬的用户，您的订单..."
  }
}
```

后端代码在收到这个 JSON 后，**必须**使用 Pydantic 或类似的数据验证库，根据预定义的 Schema 进行严格校验：

```python
from pydantic import BaseModel, EmailStr
from typing import Literal

class SendEmailArgs(BaseModel):
  to: EmailStr
  subject: str
  body: str

# 假设 ai_output 是从 LLM 获取的 JSON 字符串
try:
  parsed_output = json.loads(ai_output)
  if parsed_output.get('tool_name') == 'send_email':
    # Pydantic 会自动校验数据类型、格式（如 EmailStr）
    validated_args = SendEmailArgs(**parsed_output['arguments'])
  else:
    # 处理未知工具
    ...
except (json.JSONDecodeError, ValidationError) as e:
  # 校验失败，记录错误，准备返回给 AI
  error_message = f"参数校验失败: {e}"
  ...
```

**校验内容应包括**：

- **类型**：`to` 是不是字符串？
- **格式**：`to` 是不是合法的邮箱地址？
- **范围/枚举**：`priority` 是不是在 `['low', 'medium', 'high']` 之中？
- **权限**：当前用户是否有权限向 `to` 这个邮箱地址发信？



即使参数校验通过，工具的执行也应被隔离。特别是对于文件操作、网络请求、命令执行等敏感操作。

- **文件操作**：限制在特定的、预分配的目录内。
- **网络访问**：通过防火墙或特定的网络策略限制可访问的域名和端口。
- **代码执行**：在 Docker 容器或 WebAssembly (WASM) 等沙箱环境中运行。



将工具的执行结果（无论是成功的数据、确认信息，还是失败的错误堆栈）作为新的上下文，追加到对话历史中，再发给 AI，让它根据结果决定下一步行动。



## 第三章：构建“容错系统”—— 优雅地处理通信与行动的失败

### 错误分类

- **可恢复错误**：瞬时网络抖动、偶尔的格式错误。这类错误可以通过重试来解决。
- **不可恢复错误**：持续的逻辑错误（如 AI 始终无法理解指令）、权限问题、资源不存在。这类错误需要中断流程并告警。



### 容错模式

1. **简单重试**
   适用于网络请求等瞬时错误。设置最大重试次数和指数退避策略。

2. **带修复指令的重试**
   这是处理结构化输出和工具调用校验失败的神器。当校验失败时，不要直接放弃，而是将具体的错误信息反馈给 AI，让它自我修正。

   ```python
   你之前的输出无法被解析或校验失败。
   错误信息：字段 'priority' 的值 'urgent' 不在允许的枚举值 ['low', 'medium', 'high'] 之内。
   原始输出：{"tool_name": "create_task", "arguments": {"title": "Fix bug", "priority": "urgent"}}
   请根据上述错误修正你的输出，严格遵守 Schema 定义，只返回 JSON 对象，不要包含任何其他文字。
   ```

3. **优雅降级**

   - **转人工**：将失败的请求标记下来，转入人工处理队列。

   - **返回友好提示**：向用户返回一个通用的、预设的友好错误信息，而不是暴露技术细节。

   - **启用备用逻辑**：调用一个更简单的、不依赖 LLM 的传统逻辑来完成部分功能。



### 幂等性：防止“重复执行”的护栏

在网络通信中，请求可能会被重复发送。如果你的工具不是幂等的，重复执行可能导致严重后果（如重复创建订单、重复发送邮件）。

**所有工具的实现都必须是幂等的。**

**实现思路**：

- **天然幂等**：查询类操作（`get_user_info`）天然幂等。
- 业务逻辑保证幂等：
  - `create_order(order_id, ...)`：在函数内部，先检查 `order_id` 是否已存在。如果存在，直接返回已存在的订单对象；如果不存在，才执行创建。
  - `send_notification(notification_id, ...)`：记录已发送的通知 ID，发送前先检查。



## 第四章：建立“质量保证”—— 持续的评估与回归测试

可靠性不是一劳永逸的，它需要持续的度量和守护。



### 极星指标：结构化正确率

这是衡量你系统稳健性的核心指标。

**定义**：`结构化正确率 = (模型输出可被成功解析并通过业务逻辑校验的次数) / (总请求次数)`

这个指标直接反映了你的 AI Agent 能在多大程度上“一次做对”。你应该在生产环境中持续监控这个指标。



### 失败模式分析

定期对解析或校验失败的案例进行聚类分析。

- 是不是某个特定的字段经常出错？ -> 优化提示词或 Grammar。
- 是不是模型在处理长文本时更容易出错？ -> 考虑截断或分块策略。
- 是不是某个工具的参数描述有歧义？ -> 优化工具的 Schema 描述。

通过数据驱动的方式，不断迭代和优化你的系统。





### 端到端回归测试集

建立一套覆盖核心业务场景、包含各种边界情况的“红线”用例集。

- **正常场景**：标准的用户请求。
- **边界场景**：空字符串、超长文本、特殊字符。
- **异常场景**：恶意的输入、试图越权的操作。

将这些用例自动化，并纳入 CI/CD 流程。每次更新提示词、模型版本、工具函数或校验逻辑时，都必须运行这个回归测试集，确保变更没有破坏系统的可靠性。





## 结论：稳健性是 AI 工程化的基石

将 LLM 从一个有趣的“玩具”转变为一个可信的“生产级组件”，其间的鸿沟正是由可靠性、安全性和可维护性构成的。

通过定义严格的**通信协议（结构化输出）\**和\**行为准则（工具调用）**，我们为 AI Agent 套上了“缰绳”。通过设计周全的**容错机制**和**质量保证体系**，我们为系统装上了“安全带”和“仪表盘”。

记住，在 AI 工程化的道路上，稳健性不是可选项，而是基石。只有构建了一个足够可信的系统，我们才能真正释放 AI 的潜力，让它成为我们业务中那位最可靠的“员工”。

