主要是三个核心阶段

1. **预训练**：构建世界观与知识体系
2. **指令微调**：学会与人对话
3. **人类反馈强化学习**：精炼言行，符合人类偏好

### 预训练

预训练是是最基础、最耗时、最耗费算力的阶段。使用来自互联网、书籍、学术论文等来源的万亿级 toke 组成的海量文本。

目标是让模型从海量无标注文本中学习“语言”和“世界”的统计规律。

核心任务是**自监督学习**。具体来说，是 **“下一个词预测”**。

通过预测以及和真实下一个词的比较，计算差距（损失），利用反向传播算法调整模型内部数以亿计的参数（神经网络的权重和偏置）。

**这个阶段的模型看作一个“饱读诗书但未经世事的隐士”**。他拥有庞大的知识库，能进行流畅的文本续写，但他还不懂得如何与人进行有问有答、有帮助、安全的对话。



### 指令微调

通过这个阶段，教会模型理解并执行人类的指令，如回答问题、写邮件、总结文章等。

需要人工精心构建的 **“指令-回答”** 对数据集。比如：

- 指令：“请用一句话解释什么是光合作用。”
- 回答：“光合作用是植物利用光能将二氧化碳和水转化为有机物和氧气的过程。”

我们使用这个高质量的指令数据集，在已经预训练好的模型上进行 **有监督微调**。

训练方式依然是预测下一个词，但此时的输入是“指令”，期望的输出是“高质量的回答”。

**经过这个阶段，我们的“隐士”开始步入社会，学会了基本的社交礼仪。** 他现在能够理解你的问题并给出相关的回答，而不是自顾自地续写。

但是，他的回答可能还不够精准、有用，或者有时会产生幻觉（编造事实），风格也可能不一致。



### 人类反馈强化学习

通过这个阶段，让模型的输出更加符合人类的主观偏好（更 helpful, honest, harmless）。

