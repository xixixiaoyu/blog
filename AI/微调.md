预训练模型知识风格都是固定了的。

如果我们想让模型学习新的知识，掌握新的风格，这时微调是一个很好的方案。



#### 全参数微调 - “全员再培训”

我们让模型在特定数据上重新学习，并**更新所有的权重参数**。

效果通常最好，但是需要巨大的计算资源和存储空间（原始模型 + 所有梯度）。



#### 参数高效性微调 - “聘请专家顾问团”

目前的主流和未来方向。

核心思想是：**冻结预训练模型的大部分参数，只训练一小部分新增的适配器参数**。



常见的 PET 技术包括：

- **LoRA**：假设模型参数的变化是低秩的。我们不做全参数更新，而是用两个小得多的矩阵（A 和 B）的乘积来模拟这个更新量。效果好，训练量小，速度快，存储成本低（只需保存 A 和 B）
- **QLoRA**：在 LoRA 的基础上更进一步，将预训练模型量化为 4-bit，同时所有计算仍用 16-bit 进行。能使得在消费级显卡（如 24GB 显存）上微调大型模型（如 70B）成为可能
- **P-Tuning / Prefix-Tuning**：在模型的输入前添加一段可训练的“软提示”（连续向量），通过优化这段提示来引导模型产生期望的输出



#### 实践步骤

- 定义目标，想让模型学会什么
- 准备高质量数据（通常需要几百到几千条）通常组织成 `{“instruction”: “...”, “input”: “...”, “output”: “...”}` 的对话形式
- 选择全参数微调还是 LoRA/QLoRA 等高效方法
- 训练与评估
  - 在训练集上训练模型。
  - 在**未见过的验证集**上评估效果，防止过拟合。
  - 评估指标可以是困惑度，但更重要的是**人工评测**，看输出是否满足预期
- **部署应用**：将微调好的模型部署到生产环境，提供服务