# 写作提示 —— LLMOps 与评估框架（LangSmith、Ragas、DeepEval）

使用说明：
- 生成评估与运维的落地指南，覆盖离线数据集、在线 A/B、自动化评测管线。

生成目标：
- 介绍常见评估工具与框架（LangSmith、Ragas、DeepEval），各自适用场景。
- 设计离线/在线评测、回归数据集维护、报表与阈值门控（Quality Gate）。
- 将评估与监控串联到 CI/CD 与发布流程。

大纲建议：
1. 评估目标与指标（任务定义、Rubric、自动判分）
2. 框架与工具对比（能力、易用性、生态）
3. 离线评测与回归（数据集、黄金样例、快照）
4. 在线 A/B 与门控（实验设计、阈值与回滚）
5. 报表与可视化（仪表板、趋势、告警）
6. 与 CI/CD 的衔接（测试、发布与回归）

输出格式要求：
- Markdown；附最小评测管线示例与指标定义模板。
- 给出数据集版本化与治理建议。

质量检查清单：
- 评估可执行且可复现；指标与阈值明确。
- 有回归与门控，避免质量波动上线。
- 与监控和发布流程形成闭环。

