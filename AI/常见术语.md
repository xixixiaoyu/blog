### 1. Token (词元)

LLM 处理文本的最小、不可再分的单元，它不等于单词或字符。

想象一下 JavaScript 代码被 V8 引擎解析。引擎不会把 `const a = 1;` 当作一个整体，而是会分解成 `const`、`a`、`=`、`1`、`;` 这些“词法单元”。

Token 就是 LLM 的“词法单元”。例如，`"unhappiness"` 可能被分解为 `"un"`、`"happi"`、`"ness"` 三个 token。

API 调用费用几乎完全按 Token 数量计算（输入 + 输出）。理解 Token 能帮你精确预估成本。一个长 prompt 可能比想象中贵得多。

处理更多 Token 意味着更高的计算延迟。优化 Prompt 长度就是优化 API 响应时间。

Context Window 的大小就是用 Token 来衡量的。你需要像管理数据库连接池一样，精打细算地使用 Token 预算。

```python
# 使用 tiktoken 库（OpenAI 的官方分词器）来感受 Token
import tiktoken

encoder = tiktoken.encoding_for_model('gpt-3.5-turbo')
text = "Hello, world! 你好，世界！"
token_ids = encoder.encode(text)
token_count = len(token_ids)

print(f"文本: '{text}'")
print(f"Token IDs: {token_ids}")
print(f"Token 数量: {token_count}") # 输出可能不是 10，而是 8 或其他数字
# 这让你直观理解，Token 不是简单的字符计数
```



### 2. Embedding (嵌入向量)

将文本、图片等非结构化数据转换为高维空间中的稠密数值向量，用于表示其语义信息。

Embedding 就像为每个商品在电商系统中生成的“特性指纹”。一个“苹果手机”的向量，在“电子产品”、“昂贵”、“通讯”这些维度上值会很高，而在“水果”、“便宜”、“食物”维度上值会很低。两个向量在空间中的距离，代表了它们语义上的相似度。

这是实现“懂你”的搜索的核心。用户搜“能打电话的平板”，你可以通过 Embedding 找到“大屏手机”，而不仅仅是匹配关键词。

计算用户浏览内容的 Embedding 和商品 Embedding 的相似度，实现精准推荐。

对文本进行 Embedding 后，可以用传统的机器学习算法（如 K-Means）进行聚类，自动发现文章主题或用户群体。

```javascript
// 伪代码：调用 Embedding API
async function getEmbedding(text) {
  const response = await fetch('https://api.example.com/v1/embeddings', {
    method: 'POST',
    body: JSON.stringify({
      input: text,
      model: 'text-embedding-3-small' // 指定 embedding 模型
    })
  })
  const data = await response.json()
  return data.data[0].embedding // 返回一个浮点数数组，如 [0.01, -0.05, ..., 0.23]
}

const vector1 = await getEmbedding('全栈开发者')
const vector2 = await getEmbedding('软件工程师')
// vector1 和 vector2 在高维空间中会非常接近
```



### 3. LLM (大语言模型)

**一句话定义**：一个通过在海量文本数据上进行预训练，从而获得强大语言理解和生成能力的超大型神经网络。

LLM 就像一个封装得极好、功能极其强大的“黑盒 API”。你给它一个字符串（Prompt），它返回一个字符串。你不需要关心它内部的亿万个参数，就像你调用 Stripe API 支付时，不需要关心其内部账务系统一样。它的核心能力是“文本的概率分布预测”。

选择哪个 LLM（OpenAI GPT-4, Anthropic Claude, 开源 Llama）是架构决策。它影响成本、性能、数据隐私和功能上限。

LLM 是现代 AI 应用的“计算引擎”。你的应用逻辑，很大程度上是围绕如何设计 Prompt、处理其输出来构建的。

你需要像集成任何第三方服务（如数据库、消息队列）一样来集成它，考虑重试、降级、缓存等策略。

```javascript
// 伪代码：调用 LLM Completion API
async function askLLM(question) {
  const response = await fetch('https://api.example.com/v1/chat/completions', {
    method: 'POST',
    body: JSON.stringify({
      model: 'gpt-4-turbo',
      messages: [{ role: 'user', content: question }]
    })
  })
  const data = await response.json()
  return data.choices[0].message.content
}

askLLM('解释一下什么是 API？')
```



### 4. Prompt & Prompt Engineering (提示词与提示词工程)

Prompt 是你给 LLM 的指令和输入；Prompt Engineering 是设计和优化这些指令，以引导 LLM 产生高质量、符合预期输出的技术与艺术。

Prompt 就像是你写给一位能力超强但毫无背景知识的“实习生”的任务清单。清单写得越清晰、越结构化、给的示例越丰富，实习生交出的成果就越符合你的要求。Prompt Engineering 就是学习如何写出这份完美的任务清单。

用户与 AI 的交互质量，几乎完全由 Prompt 决定。好的 Prompt 能让产品显得“智能”，差的则显得“愚蠢”。

一个精心设计的 Prompt，可能比一个冗长模糊的 Prompt 花费更少 Token、响应更快，且效果更好。这是性价比最高的优化手段。

通过结构化 Prompt（如 JSON、XML 格式），你可以让 LLM 输出结构化的数据，便于后端解析和处理，提高系统的可靠性。

```javascript
// 一个结构化的 Prompt 示例
const systemPrompt = `
  你是一个专业的 JSON 格式化工具。
  用户会给你一段文本，你需要将其中的关键信息提取并格式化为 JSON 对象。
  如果无法提取，请返回一个空的 JSON 对象 {}。
`
const userPrompt = `
  用户张三，购买了商品 A，数量为 2，收货地址是北京市朝阳区。
`

const fullPrompt = [
  { role: 'system', content: systemPrompt },
  { role: 'user', content: userPrompt }
]

// 期望 LLM 返回: { "user": "张三", "product": "A", "quantity": 2, "address": "北京市朝阳区" }
```



### 5. Context Window (上下文窗口)

LLM 在单次交互中能够处理的最大 Token 数量，它定义了模型的“短期记忆”上限。

Context Window 就像是函数调用栈的最大深度，或者是 HTTP 请求体的最大大小限制。一旦你传入的内容（Prompt + 历史对话 + 生成内容）超过这个限制，程序就会报错（或被截断）。你必须在设计时时刻考虑这个限制。

对于聊天机器人，你需要管理对话历史。当历史过长时，必须采用策略（如摘要、只保留最近 N 轮）来确保不超出窗口。

要分析一本 100 页的 PDF，你不能直接扔给 LLM。必须将其“分块”，然后通过 RAG 等技术分批处理。

不同模型的 Context Window 大小不同（如 GPT-3.5-turbo 是 16k，而 Claude 3 可达 200k）。处理长文本任务时，这是关键的选型指标。

```javascript
// 伪代码：管理对话历史以适应 Context Window
const MAX_CONTEXT_TOKENS = 4000 // 为生成预留空间
let conversationHistory = []

function addToHistory(role, content) {
  // 简化版：假设我们能估算 token 数
  const newTokens = estimateTokens(content)
  if (getCurrentTokens(conversationHistory) + newTokens > MAX_CONTEXT_TOKENS) {
    // 策略：移除最早的对话，直到有足够空间
    while (getCurrentTokens(conversationHistory) + newTokens > MAX_CONTEXT_TOKENS) {
      conversationHistory.shift() // 移除最旧的一对对话
    }
  }
  conversationHistory.push({ role, content })
}
```



### 6. RAG (Retrieval-Augmented Generation)

一种结合了信息检索和文本生成的技术，它先从外部知识库中查找相关信息，再将这些信息作为上下文提供给 LLM，以生成更准确、更具体的回答。

这就像一个“开卷考试”的学生。面对一个问题（Query），他不是凭空回答（纯 LLM），而是先去图书馆（向量数据库）查找相关的教科书和笔记（检索到的文档片段），然后基于这些资料来组织答案（生成）。RAG 就是这个“先检索，后生成”的过程。

LLM 的知识截止于训练数据。RAG 让它能回答关于最新事件、公司内部文档等私有知识的问题。

LLM 的回答基于你提供的“证据”，大大减少了胡编乱造的可能性。你甚至可以在回答中附上引用来源。

相比于频繁地 Fine-tuning，更新知识库（向量数据库）要便宜和快速得多。这是目前构建企业级知识问答应用的主流架构。

```javascript
// 伪代码：RAG 流程
async function ragQuery(userQuestion) {
  // 1. 检索
  const questionEmbedding = await getEmbedding(userQuestion)
  const relevantDocs = await vectorDB.query(questionEmbedding, { topK: 5 })

  // 2. 增强 Prompt
  const contextText = relevantDocs.map(doc => doc.content).join('\n---\n')
  const prompt = `
    根据以下上下文回答问题。如果上下文中没有相关信息，请回答“我无法根据已知信息回答该问题”。

    上下文：
    ${contextText}

    问题：${userQuestion}
  `

  // 3. 生成
  const answer = await askLLM(prompt)
  return answer
}
```



### 7. Fine-tuning (微调)

在一个已经预训练好的基础模型上，使用自己特定的、较小的数据集进行额外训练，以调整模型权重，使其适应特定任务或领域。

这就像你拿到了一个功能强大的开源框架（如 React），但你公司的业务流程非常特殊。你不是每次都通过 props 传递复杂配置来让它工作（类似 Prompt Engineering），而是直接修改框架的源码，让它“原生”支持你的业务逻辑（类似 Fine-tuning）。你改变了模型本身的行为。

这样当需要 LLM 以非常特定的格式（如 JSON Schema）、语气（如莎士比亚风格）或领域术语（如法律文书）进行输出时，Fine-tuning 比 Prompt Engineering 更稳定、更高效。

对于需要深度内化的知识（如公司的核心代码逻辑、复杂的业务规则），Fine-tuning 可以让模型“记住”它们，而不是每次都去检索。

Fine-tuning 需要高质量的数据、计算资源和 MLOps 经验，成本远高于 RAG。通常是在 RAG 无法满足需求时才考虑的“重武器”。

```bash
# 伪代码：通常通过 CLI 工具或 SDK 进行
# 1. 准备数据集 (JSONL 格式)
# {"prompt": "什么是 A？", "completion": "A 是我们公司的核心产品..."}
# {"prompt": "如何使用 B？", "completion": "使用 B 的步骤是..."}

# 2. 上传数据集并启动微调任务
openai api fine_tuning.jobs.create \
  -t "my_company_data.jsonl" \
  -m "gpt-3.5-turbo" \
  --suffix "companyBot"

# 3. 等待训练完成，然后使用新的模型 ID (e.g., gpt-3.5-turbo:companyBot) 进行调用
```



### 8. Hallucination (幻觉)

LLM 生成的不符合事实、不连贯或完全虚构的内容，即模型在“一本正经地胡说八道”。

这就像一个经验丰富的程序员，在没看清需求文档的情况下，凭“经验”和“直觉”写了一段功能代码。代码语法完美、逻辑自洽，但实现的功能完全是错的。LLM 的幻觉就是它基于概率“生成”了看似合理但与事实不符的文本。

对于医疗、法律、金融等高风险领域，幻觉是不可接受的。它直接关系到产品的可靠性和安全性。

即使是聊天机器人，频繁的幻觉也会让用户失去信任，导致产品失败。

RAG 是最主要的缓解手段。此外，还可以通过 Prompt 要求模型“只根据提供的上下文回答”、设置事实核查后端、或在 UI 上明确提示“内容由 AI 生成，请核实”等方式来管理风险。

```javascript
// 伪代码：一个可能导致幻觉的场景
const prompt = "请介绍一下贵公司在 2025 年发布的新产品 'Quantum Leap'？"

// 如果模型的知识截止于 2023 年，它可能会：
// 1. 承认不知道（理想情况）
// 2. 编造一个听起来很酷的产品细节（幻觉）
const answer = await askLLM(prompt)
// "我们的 'Quantum Leap' 产品采用了革命性的量子纠缠通信技术..."
```



### 9. Vector Database (向量数据库)

专门用于高效存储、索引和查询高维向量（Embedding）的数据库。

传统数据库（如 MySQL）用 B-Tree 索引来精确匹配 `WHERE id = 123`。向量数据库则用一种特殊的索引（如 HNSW, IVF）来快速找到“在多维空间中与给定向量距离最近的 K 个向量”。它就像一个为“相似性”而非“相等性”优化的搜索引擎。

没有向量数据库，RAG 中的“检索”步骤就无法高效实现。它是实现语义搜索的核心基础设施。

你需要选择关系型数据库还是 NoSQL 一样，现在你也需要评估和选择向量数据库（如 Pinecone, Weaviate, ChromaDB, 或 PGVector 插件）。它影响你的系统架构、部署方式和成本。

除了 RAG，它还支持以图搜图、音频搜索、推荐系统等更多依赖“相似性”匹配的功能。

```javascript
// 伪代码：向量数据库的核心操作
const vectorDB = new VectorDatabaseClient()

// 1. 插入/更新向量（通常与原始数据一起存储）
const docVector = await getEmbedding('这是一篇关于 AI 术语的文章...')
await vectorDB.upsert({
  id: 'doc_001',
  values: docVector,
  metadata: { text: '这是一篇关于 AI 术语的文章...', source: 'internal_wiki' }
})

// 2. 查询相似向量
const queryVector = await getEmbedding('什么是向量数据库？')
const results = await vectorDB.query({
  queryVector: queryVector,
  topK: 3,
  includeMetadata: true
})
// results 会包含与 query 最相似的 3 个文档片段
```



### 10. Agent (智能体)

一个使用 LLM 作为其“推理大脑”，能够自主规划任务、选择工具（API）、执行任务并根据结果反思，直至完成复杂目标的系统。

Agent 就像一个独立的项目经理。你给他一个目标：“帮我预订下周去上海的机票和酒店”。他会：

1. **规划**：分解任务为“查机票”、“订机票”、“查酒店”、“订酒店”。
2. **推理**：决定先查机票，因为日期确定了才能订酒店。
3. **行动**：调用“机票查询 API”。
4. **观察**：API 返回了几个航班选项。
5. **循环**：基于结果继续下一步（调用“酒店查询 API”），直到所有任务完成。
   LLM 就是这个项目经理的大脑，API 就是他能使用的工具。

Agent 将 AI 的能力从被动回答问题，提升到主动完成任务。这是构建自动化工作流、个人助理、代码生成等高级应用的关键。

Agent 引入了“工具调用”、“记忆管理”、“任务规划”等新组件。你需要设计一个“工具箱”（一系列可供 LLM 调用的 API），并管理 Agent 的执行循环和状态。

Agent 的自主性也带来了不确定性。如何保证它能正确使用工具？如何限制它的权限和成本？如何处理执行失败？这些都是前沿的工程挑战。

```javascript
// 伪代码：Agent 的核心循环
class Agent {
  constructor(tools, llm) {
    this.tools = tools // e.g., [{ name: 'search', func: searchApi }, { name: 'book', func: bookApi }]
    this.llm = llm
    this.memory = []
  }

  async run(goal) {
    let prompt = `你的目标是: ${goal}。你可以使用这些工具: ${JSON.stringify(this.tools)}`
    let taskCompleted = false

    while (!taskCompleted) {
      const response = await this.llm(prompt + '\n下一步行动是什么？')
      // 假设 LLM 返回: { action: 'search', args: { query: 'flight to Shanghai' } }
      const action = JSON.parse(response)

      // 执行工具
      const tool = this.tools.find(t => t.name === action.action)
      const result = await tool.func(action.args)

      // 更新记忆和 prompt
      this.memory.push({ action, result })
      prompt += `\n我执行了 ${action.action}，得到结果: ${result}`

      // 让 LLM 判断任务是否完成
      taskCompleted = await this.llm(prompt + '\n目标达成了吗？回答是或否。') === '是'
    }
  }
}
```
