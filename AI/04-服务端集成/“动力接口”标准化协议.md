
# Master Prompt: 将 AI 服务集成类比为“构建统一 API 网关”

## 1. 核心目标 (Core Goal)

你是一位经验丰富的后端架构师，正在为团队设计一个可扩展、高可用的 AI 服务集成层。你的任务是撰写一篇技术设计文档，阐述如何构建一个“统一 AI 网关 (Unified AI Gateway)”，以优雅地接入并管理像 OpenAI, Anthropic, Google Gemini 等多个第三方 AI 服务。

**核心类比**：
- **AI 服务提供商 (OpenAI, Anthropic)**: 类比为功能各异但协议不兼容的**上游微服务 (Upstream Microservices)**。
- **你的业务应用**: 类比为需要消费这些微服务能力的**下游客户端 (Downstream Clients)**。
- **统一 AI 网关**: 类比为 **Nginx, Kong, 或 Spring Cloud Gateway**。它是所有 AI 请求的唯一入口，负责协议转换、智能路由和统一治理。
- **协议转换**: 核心是应用 **适配器模式 (Adapter Pattern)**。为每个提供商实现一个适配器，将它们独特的请求/响应格式，转换为网关内部的“标准协议”。
- **标准协议**: 我们选择 **兼容 OpenAI 的 API 格式作为内部标准**。这是一个事实上的行业标准，生态工具成熟，便于客户端集成。

这篇文章的目标是提供一份可落地的工程蓝图，而不是一份空泛的战略报告。

## 2. 文章结构 (Article Structure)

**I. 标题：别让你的应用直连 OpenAI！构建统一 AI 网关的架构艺术**

**II. 引言：从“混乱”到“有序”**
   - 描绘一个痛点场景：服务 A 直连 OpenAI，服务 B 直连 Anthropic。导致密钥管理混乱、成本失控、故障时无法切换、每个服务都得重写流式处理和重试逻辑。
   - 提出解决方案：在所有应用和 AI 提供商之间，插入一个“统一 AI 网关”。
   - 核心价值主张：**“一次集成，到处使用”**。屏蔽底层复杂性，为内部开发者提供稳定、统一、易用的 AI 接入体验。

**III. 架构核心：定义我们的“标准协议”**
   - **决策**：为什么选择兼容 OpenAI 的 API 作为我们的内部标准？（生态成熟、开发者熟悉、社区支持好）
   - **协议定义 (Code Snippet)**：明确定义网关向内部暴露的核心接口。例如，一个标准化的聊天接口：
     ```typescript
     // Gateway Standard Interface: POST /v1/chat/completions
     interface StandardChatRequest {
       model: string; // e.g., 'gpt-4o', 'claude-3.5-sonnet'
       messages: { role: 'user' | 'assistant'; content: string }[];
       stream?: boolean;
       // ... other standard parameters
     }
     ```
   - **解释**：客户端只需关心这个标准接口。`model` 字段将成为网关进行“智能路由”的关键依据。

**IV. 实现关键：用“适配器模式”抹平差异**
   - **概念引入**：什么是适配器模式？它如何在这里帮助我们将 `Provider-Specific API` 转换为 `Standard API`。
   - **实战：构建 Anthropic 适配器 (Code Snippet)**
     - 展示如何将一个“标准请求”转换为 Anthropic 的格式。重点突出 `messages` 和 `system prompt` 的转换逻辑。
     ```typescript
     // Inside AnthropicAdapter.ts
     function toAnthropicRequest(request: StandardChatRequest) {
       const { model, messages, ...rest } = request;
       // Logic to correctly handle system prompts for Anthropic
       const systemPrompt = messages.find(m => m.role === 'system')?.content;
       const userMessages = messages.filter(m => m.role !== 'system');

       return {
         model: model, // The model name for Anthropic
         messages: userMessages,
         system: systemPrompt,
         ...rest
       };
     }
     ```
   - **实战：适配响应流 (Response Streaming)**
     - 讨论并对比 OpenAI 和 Anthropic 在 SSE (Server-Sent Events) 格式上的细微差异（如 `data: [DONE]` vs. `event: message_stop`）。
     - 展示适配器如何将这些差异抹平，向上游客户端只输出一种统一、标准的流式格式。

**V. 网关的“超能力”：统一的服务治理**
   - **智能路由与负载均衡**：基于请求中的 `model` 字段，或根据延迟、成本等动态策略，将请求路由到最合适的上游服务。
   - **故障转移与自动降级 (Failover & Fallback)**：
     - 场景：当 OpenAI API 响应 5xx 错误或超时。
     - 策略：网关自动捕获错误，并将请求重试到备用的 Anthropic 模型（例如，从 `gpt-4o` 降级到 `claude-3.5-sonnet`）。提供伪代码或中间件示例。
   - **统一认证与密钥管理**：客户端只持有网关的 API Key。网关负责安全地存储和使用所有上游服务的密钥。
   - **统一缓存与成本控制**：
     - 对完全相同的请求实现缓存，大幅降低成本和延迟。
     - 实现全局的、按用户/部门的速率限制和预算控制。
   - **统一日志与可观测性**：在一个地方集中记录所有 AI 请求的元数据（模型、耗时、Token 数、成本），轻松构建监控仪表盘。

**VI. 结论：AI 网关是现代技术栈的“新基建”**
   - 总结：AI 网关不是一个可选项，而是任何严肃使用 AI 的企业的必需品。它将 AI 服务从一个外部依赖，真正“内化”为平台自身的一种能力。
   - 展望：未来的网关将更加智能，集成更多模型评估、A/B 测试等高级 MLOps 功能。

## 3. 质量与风格核对清单 (Quality & Style Checklist)

- [ ] **架构图**：是否包含一张清晰的架构图，展示 Clients -> Gateway -> Adapters -> Providers 的请求流程？
- [ ] **设计模式**：是否清晰地解释了“适配器模式”在其中的应用？
- [ ] **代码驱动**：关键的协议定义和适配器逻辑是否提供了具体的代码示例？
- [ ] **问题导向**：文章是否始终围绕解决“多厂商、多协议”带来的工程痛点展开？
- [ ] **价值明确**：网关带来的“统一治理”价值（如容灾、缓存、控本）是否被量化和突出？
- [ ] **术语精准**：是否通篇使用后端开发者熟悉的术语（网关、上游/下游、适配器、中间件）？
