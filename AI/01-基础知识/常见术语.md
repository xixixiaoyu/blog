#### Token（词元）

**定义**：文本被模型编码后的最小语义单元，类似编译器的「词法单元」。

1 Token ≈ 0.75 个英文单词 或 1.5 个汉字。模型按 Token 计费、限流、限制上下文长度。

```js
// 场景：精确计算请求成本，避免超限
import { encode } from 'gpt-tokenizer/model/gpt-4'

function checkContextLimit(
  prompt: string,
  maxTokens: number = 128000
): boolean {
  const tokens = encode(prompt)
  // 预留 500 tokens 给模型回复
  return tokens.length + 500 <= maxTokens
}

// 实际调用前检查，避免浪费 API 调用
if (!checkContextLimit(userInput)) {
  // 前端分块策略：按段落拆分
  const chunks = splitByParagraph(userInput)
  // 逐块处理...
}
```



#### Embedding（嵌入向量）

**定义**：将文本/图像转换为固定长度的浮点数数组（如 1536 维），使语义相近的内容在向量空间中距离更近。这是 RAG、推荐、聚类的核心技术。

