# 写作提示 —— 请求模式与并发

使用说明：
- 介绍在 AI 应用中常见的请求模式与并发控制方案，兼顾稳定性与成本。

生成目标：
- 总结串行、并行、批处理、队列化、幂等与重试退避策略。
- 提供服务端代理层的并发控制示例（速率限制、令牌桶、队列长度）。
- 考虑流式响应与 UI 体验的并发设计。

大纲建议：
1. 需求与约束（速率限制、配额、用户体验）
2. 请求模式设计（串行、并行、批量、队列）
3. 并发控制（限流、熔断、重试与退避、超时与取消）
4. 流式响应的并发策略（分片渲染、优先级调度）
5. 监控与预警（延迟、错误率、排队时间、丢弃率）
6. 成本与资源权衡（缓存、结果复用、降级）

输出格式要求：
- Markdown；附最小代理层实现示例（Node/Nest）。
- 给出参数建议与默认值参考。

质量检查清单：
- 并发策略可落地，有代码或伪代码。
- 兼顾用户体验与成本控制，具备可观测性设计。
- 明确异常与退避策略，避免雪崩效应。

默认技术栈：TypeScript + NestJS

限流与速率（Throttler 示例）：

依赖：`npm i @nestjs/throttler`

```ts
// src/app.module.ts
import { Module } from '@nestjs/common';
import { ThrottlerModule } from '@nestjs/throttler';

@Module({
  imports: [ThrottlerModule.forRoot({ ttl: 60, limit: 120 })], // 每分钟 120 次
})
export class AppModule {}
```

```ts
// src/llm.controller.ts
import { Controller, Post, Body, UseGuards } from '@nestjs/common';
import { ThrottlerGuard } from '@nestjs/throttler';

@Controller('llm')
@UseGuards(ThrottlerGuard)
export class LlmController {
  @Post('chat')
  async chat(@Body() body: { prompt: string }) {
    // 调用上游模型（省略）
    return { ok: true };
  }
}
```

队列与并发（p-queue 示例）：

依赖：`npm i p-queue`

```ts
// src/concurrency.service.ts
import { Injectable } from '@nestjs/common';
import PQueue from 'p-queue';

@Injectable()
export class ConcurrencyService {
  private queue = new PQueue({ concurrency: 4 }); // 并发上限

  enqueue<T>(task: () => Promise<T>) {
    return this.queue.add(task, { priority: 1 });
  }
}
```

批处理示例（合并小请求，降低成本）：

```ts
// src/batcher.ts
import { Subject } from 'rxjs';
import { bufferTime, filter } from 'rxjs/operators';

type Item = { id: string; text: string };

const in$ = new Subject<Item>();
in$.pipe(bufferTime(50), filter((batch) => batch.length > 0)).subscribe(async (batch) => {
  // 将 batch 合并为一个上游请求（如 embedding）
  // const vectors = await embed(batch.map(b => b.text));
  // 将结果按 id 分发（省略）
});

export function submit(item: Item) { in$.next(item); }
```

超时、取消与退避（文字与参数建议）：
- 请求超时：整体 30s；可分层设置（连接、读、写）。
- 重试退避：指数退避（200ms, 500ms, 1s），最多 2 次；对 429/503 生效。
- 取消：SSE 使用 `EventSource.close()`；WS 发送 `cancel` 事件；服务端在监听到取消后释放资源（中止上游流）。

流式并发策略与 UI：
- 多请求并行渲染：按消息分区渲染；避免多个流挤占渲染主线程，可用 `requestAnimationFrame` 合帧。
- 优先级调度：用户输入优先，后台任务降级；支持暂停/恢复；必要时丢弃过期流的尾部。

观测与告警：
- 指标：排队时间、并发数、丢弃率、超时率、重试次数。
- 日志字段：`queueSize`、`queueWaitMs`、`concurrency`、`retryCount`、`statusCode`。
- 阈值：队列长度 > N 告警，丢弃率 > M% 告警；自动降级策略触发。
